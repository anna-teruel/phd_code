{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import cebra\n",
    "from cebra import CEBRA\n",
    "import pandas as pd\n",
    "import tables\n",
    "import sys\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load all S_aligned files and save them as hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/annateruel/Desktop/results_calcium/AD22092'\n",
    "\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        if file.endswith('S_aligned.csv'):\n",
    "            file_path = os.path.join(root, file)  # Get the full path to the CSV file\n",
    "            # Use a key based on the relative path of the CSV file to store it in the dictionary\n",
    "            key = os.path.relpath(file_path, path).replace('S_aligned.csv', '').replace(os.path.sep, '_')\n",
    "\n",
    "            # Read the CSV file into a DataFrame\n",
    "            df = pd.read_csv(file_path)\n",
    "            df = df.drop('frame', axis=1)\n",
    "            df = (df>0).astype(int) #converting all numbers above 0 to 1, so that our spikes are boolean\n",
    "\n",
    "            # Define the path to save the HDF5 file in the same directory with the same name\n",
    "            h5_file_path = os.path.splitext(file_path)[0] + '.h5'\n",
    "\n",
    "            # Save the DataFrame as an HDF5 file in the same directory\n",
    "            df.to_hdf(h5_file_path, key='data', mode='w')\n",
    "            \n",
    "            print(f\"Converted '{file}' to '{os.path.basename(h5_file_path)}' and saved in '{os.path.dirname(h5_file_path)}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a dictionary storing info from 4 different hdf5 files. Each file belongs to a different session. Total number of sessions: 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "file_path = '/Users/annateruel/Desktop/poster_sfn/calcium/control/neutro_results.hdf5'\n",
    "with h5py.File(file_path, 'r') as hdf:\n",
    "    C = hdf['estimates/C'][:]\n",
    "    \n",
    "df = pd.DataFrame(C)\n",
    "new_file_path = '/Users/annateruel/Desktop/neutro_C.h5'\n",
    "df.to_hdf(new_file_path, key='estimates/C', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "t = pd.read_hdf('/Users/annateruel/Desktop/poster_sfn/calcium/control/hab1_results.hdf5')\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.read_hdf('/Users/annateruel/Desktop/poster_sfn/calcium/dlc/concatenated_files/AD23-120-s8-anosmic_centroid.h5')\n",
    "x = b.loc[:,(slice(None), 'centroid', 'x')]\n",
    "nfp = '/Users/annateruel/Desktop/neutro_a_centroid_x.h5'\n",
    "x.to_hdf(nfp, key='centroid_x', mode='w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/annateruel/Desktop/results_calcium/AD22118'\n",
    "data = {}  # Create a dictionary to store data from each CSV file\n",
    "\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        if file.endswith('S_aligned.csv'):\n",
    "            file_path = os.path.join(root, file)  # Get the full path to the CSV file\n",
    "            # Use a key based on the relative path of the CSV file to store it in the dictionary\n",
    "            key = os.path.relpath(file_path, path).replace('S_aligned.csv', '').replace(os.path.sep, '_')\n",
    "            data[key] = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cebra\n",
    "\n",
    "# Define the directory containing the files\n",
    "directory = '/Users/annateruel/Desktop/poster_sfn/calcium/control/'\n",
    "\n",
    "# Find all files that end with 'x.h5' in the directory\n",
    "file_pattern = os.path.join(directory, '*x.h5')\n",
    "files = glob.glob(file_pattern)\n",
    "\n",
    "# Iterate over the files and load the data\n",
    "for file_path in files:\n",
    "    print(f\"Processing file: {file_path}\")\n",
    "    data = cebra.load_data(file=file_path, key='centroid_x')\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "nd = cebra.load_data(file='/Users/annateruel/Desktop/poster_sfn/calcium/control/hab1_C.h5', key='estimates/C')\n",
    "b = cebra.load_data(file='/Users/annateruel/Desktop/poster_sfn/calcium/control/hab1_centroid_x.h5', key = 'centroid_x')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CEBRA-time \n",
    "Uses time without behaviour information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iterations = 10000 \n",
    "\n",
    "cebra_time_model = CEBRA(model_architecture='offset10-model',  #CEBRA TIME model\n",
    "                        batch_size=512,\n",
    "                        learning_rate=0.05,\n",
    "                        temperature=1,\n",
    "                        output_dimension=3,\n",
    "                        max_iterations=max_iterations,\n",
    "                        distance='cosine',\n",
    "                        conditional='time',\n",
    "                        device='mps',\n",
    "                        verbose=True,\n",
    "                        time_offsets=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cebra_time_model.fit(nd) #training\n",
    "cebra_time_model.save(\"cebra_time_model_ad22092_s4.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cebra_time_model = cebra.CEBRA.load(\"cebra_time_model_ad22092_s2.pt\")\n",
    "cebra_time = cebra_time_model.transform(nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cebra.plot_embedding(embedding=cebra_time, embedding_labels=b[:,0], title='CEBRA-Behavior_s1', cmap='cebra', dpi = 200, markersize= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,5))\n",
    "\n",
    "ax1 = plt.subplot(141, projection='3d')\n",
    "ax2 = plt.subplot(142, projection='3d')\n",
    "ax3 = plt.subplot(143, projection='3d')\n",
    "\n",
    "ax1=cebra.plot_embedding(ax=ax1, embedding=cebra_time, embedding_labels=nd_s4[:,4], title='CEBRA-Time Session4')\n",
    "ax2=cebra.plot_embedding(ax=ax2, embedding=cebra_time, embedding_labels=nd_s4[:,50], title='CEBRA-Time Session4')\n",
    "ax3=cebra.plot_embedding(ax=ax3, embedding=cebra_time, embedding_labels=nd_s4[:,1], title='CEBRA-Time Session4')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CEBRA-behavior\n",
    "\n",
    "Train a model that uses positional (pose estimation) information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we\n",
    " want to run CEBRA BEHAVIOR, thus we need to use as labels our behavior from dlc, which are different h5 files. To do so, we need to merge with `pd.merge` all h5 files from dlc, because since during the recoridng we save a video every 1000 frames, we need to get one single file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_dir = '/Users/annateruel/Desktop/poster_sfn/calcium/control/'\n",
    "\n",
    "for session_dir in os.listdir(h5_dir):\n",
    "    session_path = os.path.join(h5_dir, session_dir)\n",
    "    \n",
    "    # Check if the item in the root directory is a directory itself\n",
    "    if os.path.isdir(session_path):\n",
    "        dlc_output_dir = os.path.join(session_path, 'dlc')  # Path to \"dlc\" output directory\n",
    "        \n",
    "        if os.path.exists(dlc_output_dir) and os.path.isdir(dlc_output_dir):\n",
    "            # Initialize an empty list to store DataFrames for this session\n",
    "            dataframes = []\n",
    "            \n",
    "            # Loop through h5 files in the \"dlc\" output directory\n",
    "            for h5_file in os.listdir(dlc_output_dir):\n",
    "                if h5_file.startswith(\"._\"):\n",
    "                    file_path = os.path.join(dlc_output_dir, h5_file)\n",
    "                    os.remove(file_path)\n",
    "                elif h5_file.endswith('filtered.h5'):\n",
    "                    h5_file_path = os.path.join(dlc_output_dir, h5_file)\n",
    "\n",
    "                    # Read the h5 file into a DataFrame\n",
    "                    df = pd.read_hdf(h5_file_path)\n",
    "                    # Append the DataFrame to the list\n",
    "                    dataframes.append(df)\n",
    "            \n",
    "            if dataframes:\n",
    "                # Merge all DataFrames in this session into a single DataFrame\n",
    "                merged_df = pd.concat(dataframes, axis=0)\n",
    "                \n",
    "                # Define the path to save the merged h5 file in the session directory\n",
    "                output_h5_path = os.path.join(session_path, 'merged_output.h5')\n",
    "                \n",
    "                # Save the merged DataFrame as an h5 file\n",
    "                merged_df.to_hdf(output_h5_path, key='data', mode='w')\n",
    "                \n",
    "                print(f\"Merged data saved to '{output_h5_path}' in session '{session_dir}'\")\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the centroid, to use centroid position in space as your label, because we're interested in position among space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior = pd.read_hdf('/Users/annateruel/Desktop/results_calcium/AD22092/session1/merged_output.h5')\n",
    "df = behavior.loc[:,('DLC_resnet50_ca2+imgJan30shuffle1_500000')]\n",
    "df['x_centroid'] = np.mean(df.loc[:,(slice(None), 'x')], axis=1)\n",
    "df['y_centroid'] = np.mean(df.loc[:,(slice(None), 'y')], axis=1)\n",
    "df2 = df[['x_centroid', 'y_centroid']]\n",
    "df2.to_hdf('/Users/annateruel/Desktop/results_calcium/AD22092/session1/centroid.h5', key='data', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "nd = cebra.load_data(file='/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/neutro_a_C.h5', key='estimates/C')\n",
    "b = cebra.load_data(file='/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/neutro_a_centroid_x.h5', key = 'centroid_x')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = b[:len(nd)]\n",
    "\n",
    "# Verify the lengths\n",
    "print(f\"Length of nd: {len(nd)}\")\n",
    "print(f\"Length of b: {len(b)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'time_delta' means we will use CEBRA-Behavior mode and use auxiliary behavior variable for the model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iterations = 1000\n",
    "\n",
    "cebra_behavior_model = CEBRA(model_architecture='offset10-model',\n",
    "                        batch_size=564,\n",
    "                        learning_rate=0.01,\n",
    "                        temperature=1,\n",
    "                        output_dimension=3,\n",
    "                        max_iterations=max_iterations,\n",
    "                        num_hidden_units = 16,\n",
    "                        distance='cosine',\n",
    "                        device='mps',\n",
    "                        verbose=True,\n",
    "                        time_offsets=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cebra_behavior_model.fit(nd, b)\n",
    "cebra_behavior_model.save('/Users/annateruel/Desktop/neutro.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "cebra_behavior_model = cebra.CEBRA.load('/Users/annateruel/Desktop/neutro.pt')\n",
    "cebra_behavior = cebra_behavior_model.transform(nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as pt\n",
    "import numpy as np\n",
    "\n",
    "class ROI:\n",
    "    def __init__(self, center, rad):\n",
    "        self.center = center\n",
    "        self.rad = rad\n",
    "\n",
    "    def is_point_inside_roi(self, point):\n",
    "        \"\"\"\n",
    "        Determines if a given point is inside the ellipse.\n",
    "\n",
    "        Args:\n",
    "            point (tuple): A tuple representing the (x, y) coordinates of the point to check.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if the point is inside the ellipse, False otherwise.\n",
    "        \"\"\"        \n",
    "        x, y = point\n",
    "        h, k = self.center\n",
    "        a, b = self.rad\n",
    "        return ((x - h)**2 / a**2) + ((y - k)**2 / b**2) <= 1\n",
    "\n",
    "def load_roi_data(roi_file):\n",
    "    roi_data = pd.read_hdf(roi_file)\n",
    "    print(\"ROI Data Structure:\")\n",
    "    print(roi_data.head())  # Print a sample of the data for inspection\n",
    "    return roi_data\n",
    "\n",
    "def compute_roi_parameters(x, y, w, h):\n",
    "    \"\"\"\n",
    "    Compute the center and radii of an ellipse from manual coordinates.\n",
    "\n",
    "    Args:\n",
    "        x (int): The x-coordinate of the top-left corner.\n",
    "        y (int): The y-coordinate of the top-left corner.\n",
    "        w (int): The width of the rectangle.\n",
    "        h (int): The height of the rectangle.\n",
    "\n",
    "    Returns:\n",
    "        center (tuple): The (x, y) coordinates of the ellipse center.\n",
    "        rad (tuple): The (a, b) radii of the ellipse.\n",
    "    \"\"\"\n",
    "    center_x = x + w / 2\n",
    "    center_y = y + h / 2\n",
    "    a = w / 2\n",
    "    b = h / 2\n",
    "    \n",
    "    return (center_x, center_y), (a, b)\n",
    "\n",
    "def plot_data_with_rois(roi_data, rois):\n",
    "    \"\"\"\n",
    "    Plot the data points with different colors based on the ROI.\n",
    "\n",
    "    Args:\n",
    "        roi_data (DataFrame): The data points to be plotted.\n",
    "        rois (list of ROI): The list of ROI objects.\n",
    "    \"\"\"\n",
    "    colors = ['blue', 'red', 'green', 'purple']  # Add more colors if you have more ROIs\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    for index, row in roi_data.iterrows():\n",
    "        point = (row['axis-0'], row['axis-1'])\n",
    "        color = 'gray'  # Default color for points not in any ROI\n",
    "        for i, roi in enumerate(rois):\n",
    "            if roi.is_point_inside_roi(point):\n",
    "                color = colors[i % len(colors)]\n",
    "                break\n",
    "        plt.scatter(point[0], point[1], color=color)\n",
    "    \n",
    "    for roi in rois:\n",
    "        ellipse = plt.Circle(roi.center, roi.rad[0], roi.rad[1], color='black', fill=False)\n",
    "        plt.gca().add_patch(ellipse)\n",
    "\n",
    "    plt.xlabel('Axis-0')\n",
    "    plt.ylabel('Axis-1')\n",
    "    plt.title('Data Points with ROIs')\n",
    "    plt.show()\n",
    "\n",
    "# Manual coordinates for ROIs\n",
    "roi0_center, roi0_radii = compute_roi_parameters(158, 125, 109, 102)\n",
    "roi1_center, roi1_radii = compute_roi_parameters(144, 340, 119, 116)\n",
    "\n",
    "roi0 = ROI(roi0_center, roi0_radii)\n",
    "roi1 = ROI(roi1_center, roi1_radii)\n",
    "\n",
    "rois = [roi0, roi1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "\n",
    "def plot_cebra_behavior(cebra_behavior, labels, output_path=None, roi0=None, roi1=None, elev=30, azim=45, axis_order=(0, 1, 2), save_fig=False):\n",
    "    # Apply axis order to the data\n",
    "    x = cebra_behavior[:, axis_order[0]]\n",
    "    y = cebra_behavior[:, axis_order[1]]\n",
    "    z = cebra_behavior[:, axis_order[2]]\n",
    "\n",
    "    # Define ROI conditions for plotting\n",
    "    if roi0 is not None and roi1 is not None:\n",
    "        in_roi0 = [roi0.is_point_inside_roi((point[0], point[1])) for point in labels]\n",
    "        in_roi1 = [roi1.is_point_inside_roi((point[0], point[1])) for point in labels]\n",
    "\n",
    "        # Debugging: Check number of points in each ROI\n",
    "        print(f\"Points in ROI0: {sum(in_roi0)}, Points in ROI1: {sum(in_roi1)}\")\n",
    "\n",
    "        # Debugging: Print some points to verify correctness\n",
    "        for i, (point, roi0_flag, roi1_flag) in enumerate(zip(labels, in_roi0, in_roi1)):\n",
    "            if i < 10 or roi1_flag:  # Print first 10 points and any point in ROI1\n",
    "                print(f\"Point {i}: {point}, in ROI0: {roi0_flag}, in ROI1: {roi1_flag}\")\n",
    "\n",
    "    # Plotting code\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    colors = ['gray'] * len(cebra_behavior)\n",
    "    if roi0 is not None and roi1 is not None:\n",
    "        for idx, in_roi in enumerate(in_roi0):\n",
    "            if in_roi:\n",
    "                colors[idx] = 'deepskyblue'\n",
    "        for idx, in_roi in enumerate(in_roi1):\n",
    "            if in_roi:\n",
    "                colors[idx] = 'magenta'\n",
    "\n",
    "    scatter = ax.scatter(x, y, z, c=colors, alpha=0.5, s=20)\n",
    "\n",
    "    # Rotate the view\n",
    "    ax.view_init(elev=elev, azim=azim)\n",
    "    \n",
    "    ax.grid(False)\n",
    "    ax.xaxis.pane.fill = False\n",
    "    ax.yaxis.pane.fill = False\n",
    "    ax.zaxis.pane.fill = False\n",
    "    ax.xaxis.pane.set_edgecolor('white')\n",
    "    ax.yaxis.pane.set_edgecolor('white')\n",
    "    ax.zaxis.pane.set_edgecolor('white')\n",
    "    ax.xaxis.pane.set_alpha(0)\n",
    "    ax.yaxis.pane.set_alpha(0)\n",
    "    ax.zaxis.pane.set_alpha(0)\n",
    "\n",
    "    fig.patch.set_facecolor('#17171D')\n",
    "    ax.set_facecolor('#17171D')\n",
    "\n",
    "    plt.title('3D Embedding Space with ROIs Highlighted')\n",
    "    ax.set_xlabel('Embedding Dim 1')\n",
    "    ax.set_ylabel('Embedding Dim 2')\n",
    "    ax.set_zlabel('Embedding Dim 3')\n",
    "\n",
    "    if save_fig and output_path:\n",
    "        if not output_path.lower().endswith('.svg'):\n",
    "            output_path = output_path.rstrip('/') + '/embedding_space_with_rois.svg'\n",
    "        plt.savefig(output_path, format='svg', dpi=300, bbox_inches='tight', facecolor=fig.get_facecolor())\n",
    "    else:\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cebra_behavior(cebra_behavior, b, '/Users/annateruel/Desktop/embedding_space_with_rois.svg', roi0, roi1, axis_order=(0, 1, 2), save_fig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('dark_background')  # plots with black background\n",
    "cebra.plot_embedding(embedding=cebra_behavior, embedding_labels=b[:,0], title='CEBRA-Behavior_s1', cmap='cebra', dpi = 300, markersize= 15)\n",
    "plt.savefig('/Users/annateruel/Desktop/test_12m.svg', format='svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONSISTENCY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "hab1_n = cebra.load_data(file='/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/hab1_a_C.h5', key='estimates/C')\n",
    "hab1_b = cebra.load_data(file='/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/hab1_a_centroid_x.h5', key = 'centroid_x')\n",
    "hab1_model = cebra.CEBRA.load('/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/embeddings/hab1.pt')\n",
    "hab1 = hab1_model.transform(hab1_n)\n",
    "\n",
    "hab2_n = cebra.load_data(file='/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/hab2_a_C.h5', key='estimates/C')\n",
    "hab2_b = cebra.load_data(file='/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/hab2_a_centroid_x.h5', key = 'centroid_x')\n",
    "hab2_model = cebra.CEBRA.load('/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/embeddings/hab2.pt')\n",
    "hab2 = hab2_model.transform(hab2_n)\n",
    "\n",
    "trn1_n = cebra.load_data(file='/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/trn1_a_C.h5', key='estimates/C')\n",
    "trn1_b = cebra.load_data(file='/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/trn1_a_centroid_x.h5', key = 'centroid_x')\n",
    "trn1_model = cebra.CEBRA.load('/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/embeddings/trn1.pt')\n",
    "trn1 = trn1_model.transform(trn1_n)\n",
    "\n",
    "trn2_n = cebra.load_data(file='/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/trn2_a_C.h5', key='estimates/C')\n",
    "trn2_b = cebra.load_data(file='/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/trn2_a_centroid_x.h5', key = 'centroid_x')\n",
    "trn2_model = cebra.CEBRA.load('/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/embeddings/trn2.pt')\n",
    "trn2 = trn2_model.transform(trn2_n)\n",
    "\n",
    "test1_n = cebra.load_data(file='/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/test1_a_C.h5', key='estimates/C')\n",
    "test1_b = cebra.load_data(file='/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/test1_a_centroid_x.h5', key = 'centroid_x')\n",
    "test1_model = cebra.CEBRA.load('/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/embeddings/test1.pt')\n",
    "test1 = test1_model.transform(test1_n)\n",
    "\n",
    "test2_n = cebra.load_data(file='/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/test2_a_C.h5', key='estimates/C')\n",
    "test2_b = cebra.load_data(file='/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/test2_a_centroid_x.h5', key = 'centroid_x')\n",
    "test2_model = cebra.CEBRA.load('/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/embeddings/test2.pt')\n",
    "test2 = test2_model.transform(test2_n)\n",
    "\n",
    "neutro_n = cebra.load_data(file='/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/neutro_a_C.h5', key='estimates/C')\n",
    "neutro_b = cebra.load_data(file='/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/neutro_a_centroid_x.h5', key = 'centroid_x')\n",
    "neutro_model = cebra.CEBRA.load('/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/embeddings/neutro.pt')\n",
    "neutro = neutro_model.transform(neutro_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cebra\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Load data and transform using CEBRA models\n",
    "data_files = {\n",
    "    \"hab1\": {\n",
    "        \"data\": \"/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/hab1_a_C.h5\",\n",
    "        \"centroid\": \"/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/hab1_a_centroid_x.h5\",\n",
    "        \"model\": \"/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/embeddings/hab1.pt\"\n",
    "    },\n",
    "    \"hab2\": {\n",
    "        \"data\": \"/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/hab2_a_C.h5\",\n",
    "        \"centroid\": \"/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/hab2_a_centroid_x.h5\",\n",
    "        \"model\": \"/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/embeddings/hab2.pt\"\n",
    "    },\n",
    "    \"trn1\": {\n",
    "        \"data\": \"/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/trn1_a_C.h5\",\n",
    "        \"centroid\": \"/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/trn1_a_centroid_x.h5\",\n",
    "        \"model\": \"/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/embeddings/trn1.pt\"\n",
    "    },\n",
    "    \"trn2\": {\n",
    "        \"data\": \"/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/trn2_a_C.h5\",\n",
    "        \"centroid\": \"/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/trn2_a_centroid_x.h5\",\n",
    "        \"model\": \"/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/embeddings/trn2.pt\"\n",
    "    },\n",
    "    \"test1\": {\n",
    "        \"data\": \"/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/test1_a_C.h5\",\n",
    "        \"centroid\": \"/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/test1_a_centroid_x.h5\",\n",
    "        \"model\": \"/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/embeddings/test1.pt\"\n",
    "    },\n",
    "    \"test2\": {\n",
    "        \"data\": \"/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/test2_a_C.h5\",\n",
    "        \"centroid\": \"/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/test2_a_centroid_x.h5\",\n",
    "        \"model\": \"/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/embeddings/test2.pt\"\n",
    "    },\n",
    "    \"neutro\": {\n",
    "        \"data\": \"/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/neutro_a_C.h5\",\n",
    "        \"centroid\": \"/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/neutro_a_centroid_x.h5\",\n",
    "        \"model\": \"/Users/annateruel/Desktop/poster_sfn/calcium/anosmic/embeddings/neutro.pt\"\n",
    "    }\n",
    "}\n",
    "\n",
    "models = {}\n",
    "embeddings = {}\n",
    "labels = {}\n",
    "\n",
    "for session, paths in data_files.items():\n",
    "    data = cebra.load_data(file=paths[\"data\"])\n",
    "    session_labels = cebra.load_data(file=paths[\"labels\"])\n",
    "    \n",
    "    # Trim labels to match the length of data if necessary\n",
    "    min_samples = min(data.shape[0], session_labels.shape[0])\n",
    "    data = data[:min_samples]\n",
    "    session_labels = session_labels[:min_samples]\n",
    "    \n",
    "    labels[session] = session_labels[:, 0].astype(float)  # Ensure labels are 1D floats\n",
    "    model = cebra.CEBRA.load(paths[\"model\"])\n",
    "    models[session] = model\n",
    "    embeddings[session] = model.transform(data)\n",
    "    \n",
    "    # Verify the lengths and shapes\n",
    "    print(f\"Length of data ({session}): {len(data)}\")\n",
    "    print(f\"Length of labels ({session}): {len(session_labels)}\")\n",
    "    print(f\"Shape of embeddings ({session}): {embeddings[session].shape}\")\n",
    "    print(f\"Shape of labels ({session}): {labels[session].shape}\")\n",
    "\n",
    "# Function to compute the correlation between two sets of embeddings\n",
    "def compute_session_consistency(embedding1, embedding2):\n",
    "    min_length = min(embedding1.shape[0], embedding2.shape[0])\n",
    "    embedding1 = embedding1[:min_length]\n",
    "    embedding2 = embedding2[:min_length]\n",
    "    \n",
    "    correlations = []\n",
    "    for i in range(embedding1.shape[1]):\n",
    "        corr, _ = pearsonr(embedding1[:, i], embedding2[:, i])\n",
    "        correlations.append(corr)\n",
    "    return np.mean(correlations)\n",
    "\n",
    "# Compute consistency between all pairs of sessions\n",
    "session_keys = list(embeddings.keys())\n",
    "consistency_scores = {}\n",
    "\n",
    "for i in range(len(session_keys)):\n",
    "    for j in range(i + 1, len(session_keys)):\n",
    "        session1 = session_keys[i]\n",
    "        session2 = session_keys[j]\n",
    "        score = compute_session_consistency(embeddings[session1], embeddings[session2])\n",
    "        consistency_scores[(session1, session2)] = score\n",
    "\n",
    "# Print the results\n",
    "print(\"Consistency scores between sessions:\")\n",
    "for (session1, session2), score in consistency_scores.items():\n",
    "    print(f\"{session1} vs {session2}: {score}\")\n",
    "\n",
    "# Create a matrix for visualization\n",
    "consistency_matrix = np.zeros((len(session_keys), len(session_keys)))\n",
    "for (session1, session2), score in consistency_scores.items():\n",
    "    i = session_keys.index(session1)\n",
    "    j = session_keys.index(session2)\n",
    "    consistency_matrix[i, j] = score\n",
    "    consistency_matrix[j, i] = score\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(consistency_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", xticklabels=session_keys, yticklabels=session_keys)\n",
    "plt.title(\"Session Consistency Scores\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = {\n",
    "    \"alzhab2\": {\n",
    "        \"data\": \"/Users/annateruel/Desktop/AD22-118/hab2/caiman/aligned_C.h5\",\n",
    "        \"labels\": \"/Users/annateruel/Desktop/AD22-118/hab2/CEBRA/labels.h5\",\n",
    "        \"model\": \"/Users/annateruel/Desktop/AD22-118/hab2/CEBRA/cebramodelcaiman.pt\"\n",
    "    },\n",
    "    \"alztrn1\": {\n",
    "        \"data\": \"/Users/annateruel/Desktop/AD22-118/trn1/caiman/aligned_C.h5\",\n",
    "        \"labels\": \"/Users/annateruel/Desktop/AD22-118/trn1/CEBRA/labels.h5\",\n",
    "        \"model\": \"/Users/annateruel/Desktop/AD22-118/trn1/CEBRA/cebramodelcaiman.pt\"\n",
    "    },\n",
    "    \"alztest\": {\n",
    "        \"data\": \"/Users/annateruel/Desktop/AD22-118/test/caiman/aligned_C.h5\",\n",
    "        \"labels\": \"/Users/annateruel/Desktop/AD22-118/test/CEBRA/labels.h5\",\n",
    "        \"model\": \"/Users/annateruel/Desktop/AD22-118/test/CEBRA/cebramodelcaiman.pt\"\n",
    "    }\n",
    "}\n",
    "\n",
    "models = {}\n",
    "embeddings = {}\n",
    "labels = {}\n",
    "\n",
    "for session, paths in data_files.items():\n",
    "    data = cebra.load_data(file=paths[\"data\"])\n",
    "    session_labels = cebra.load_data(file=paths[\"labels\"])\n",
    "    \n",
    "    # Trim labels to match the length of data if necessary\n",
    "    min_samples = min(data.shape[0], session_labels.shape[0])\n",
    "    data = data[:min_samples]\n",
    "    session_labels = session_labels[:min_samples]\n",
    "    \n",
    "    labels[session] = session_labels[:, 0].astype(float)  # Ensure labels are 1D floats\n",
    "    model = cebra.CEBRA.load(paths[\"model\"])\n",
    "    models[session] = model\n",
    "    embeddings[session] = model.transform(data)\n",
    "    \n",
    "    # Verify the lengths and shapes\n",
    "    print(f\"Length of data ({session}): {len(data)}\")\n",
    "    print(f\"Length of labels ({session}): {len(session_labels)}\")\n",
    "    print(f\"Shape of embeddings ({session}): {embeddings[session].shape}\")\n",
    "    print(f\"Shape of labels ({session}): {labels[session].shape}\")\n",
    "\n",
    "# Function to compute the correlation between two sets of embeddings\n",
    "def compute_session_consistency(embedding1, embedding2):\n",
    "    min_length = min(embedding1.shape[0], embedding2.shape[0])\n",
    "    embedding1 = embedding1[:min_length]\n",
    "    embedding2 = embedding2[:min_length]\n",
    "    \n",
    "    correlations = []\n",
    "    for i in range(embedding1.shape[1]):\n",
    "        corr, _ = pearsonr(embedding1[:, i], embedding2[:, i])\n",
    "        correlations.append(corr)\n",
    "    return np.mean(correlations)\n",
    "\n",
    "# Compute consistency between all pairs of sessions\n",
    "session_keys = list(embeddings.keys())\n",
    "consistency_scores = {}\n",
    "\n",
    "for i in range(len(session_keys)):\n",
    "    for j in range(i + 1, len(session_keys)):\n",
    "        session1 = session_keys[i]\n",
    "        session2 = session_keys[j]\n",
    "        score = compute_session_consistency(embeddings[session1], embeddings[session2])\n",
    "        consistency_scores[(session1, session2)] = score\n",
    "\n",
    "# Print the results\n",
    "print(\"Consistency scores between sessions:\")\n",
    "for (session1, session2), score in consistency_scores.items():\n",
    "    print(f\"{session1} vs {session2}: {score}\")\n",
    "\n",
    "# Create a matrix for visualization\n",
    "consistency_matrix = np.zeros((len(session_keys), len(session_keys)))\n",
    "for (session1, session2), score in consistency_scores.items():\n",
    "    i = session_keys.index(session1)\n",
    "    j = session_keys.index(session2)\n",
    "    consistency_matrix[i, j] = score\n",
    "    consistency_matrix[j, i] = score\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(consistency_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", xticklabels=session_keys, yticklabels=session_keys)\n",
    "plt.title(\"Session Consistency Scores\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import CCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def calculate_cca_consistency_scores(emb, dataset_ids=[]):\n",
    "    \"\"\"\n",
    "    Computes the pairwise CCA scores for a list of embeddings.\n",
    "    Args:\n",
    "        emb: List of embeddings (numpy arrays).\n",
    "        dataset_ids: List of dataset IDs corresponding to the embeddings.\n",
    "    Returns:\n",
    "        scores: List of CCA similarity scores.\n",
    "        pairs: List of dataset ID pairs.\n",
    "    \"\"\"\n",
    "    if isinstance(emb, dict):\n",
    "        emb = list(emb.values())\n",
    "    if len(emb) <= 1:\n",
    "        raise ValueError(\"Provide at least 2 embeddings to compare.\")\n",
    "    if len(dataset_ids) == 0:\n",
    "        dataset_ids = list(range(len(emb)))\n",
    "    if len(emb) != len(dataset_ids):\n",
    "        raise ValueError(\"The number of embeddings must match the number of dataset IDs.\")\n",
    "    \n",
    "    scores = []\n",
    "    pairs = []\n",
    "    n_components = min([embedding.shape[1] for embedding in emb])  # Use the smallest number of components\n",
    "    \n",
    "    # Iterate through all pairs of embeddings\n",
    "    for i in range(len(emb)):\n",
    "        for j in range(i + 1, len(emb)):\n",
    "            embedding1 = emb[i]\n",
    "            embedding2 = emb[j]\n",
    "            min_length = min(embedding1.shape[0], embedding2.shape[0])\n",
    "            embedding1 = embedding1[:min_length]\n",
    "            embedding2 = embedding2[:min_length]\n",
    "            \n",
    "            cca = CCA(n_components=n_components)\n",
    "            cca.fit(embedding1, embedding2)\n",
    "            X_c, Y_c = cca.transform(embedding1, embedding2)\n",
    "            \n",
    "            correlations = [np.corrcoef(X_c[:, k], Y_c[:, k])[0, 1] for k in range(n_components)]\n",
    "            score = np.mean(correlations)\n",
    "            \n",
    "            scores.append(score)\n",
    "            pairs.append((dataset_ids[i], dataset_ids[j]))\n",
    "    \n",
    "    return scores, pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cebra\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cross_decomposition import CCA\n",
    "\n",
    "# Load data and transform using CEBRA models\n",
    "data_files = {\n",
    "    \"hab1\": {\n",
    "        \"data\": \"/Users/annateruel/Desktop/poster_sfn/calcium/control/hab1_C.h5\",\n",
    "        \"centroid\": \"/Users/annateruel/Desktop/poster_sfn/calcium/control/hab1_centroid_x.h5\",\n",
    "        \"model\": \"/Users/annateruel/Desktop/poster_sfn/calcium/control/embeddings/hab1.pt\"\n",
    "    },\n",
    "    \"hab2\": {\n",
    "        \"data\": \"/Users/annateruel/Desktop/poster_sfn/calcium/control/hab2_C.h5\",\n",
    "        \"centroid\": \"/Users/annateruel/Desktop/poster_sfn/calcium/control/hab2_centroid_x.h5\",\n",
    "        \"model\": \"/Users/annateruel/Desktop/poster_sfn/calcium/control/embeddings/hab2.pt\"\n",
    "    },\n",
    "    \"trn1\": {\n",
    "        \"data\": \"/Users/annateruel/Desktop/poster_sfn/calcium/control/trn1_C.h5\",\n",
    "        \"centroid\": \"/Users/annateruel/Desktop/poster_sfn/calcium/control/trn1_centroid_x.h5\",\n",
    "        \"model\": \"/Users/annateruel/Desktop/poster_sfn/calcium/control/embeddings/trn1.pt\"\n",
    "    },\n",
    "    \"trn2\": {\n",
    "        \"data\": \"/Users/annateruel/Desktop/poster_sfn/calcium/control/trn2_C.h5\",\n",
    "        \"centroid\": \"/Users/annateruel/Desktop/poster_sfn/calcium/control/trn2_centroid_x.h5\",\n",
    "        \"model\": \"/Users/annateruel/Desktop/poster_sfn/calcium/control/embeddings/trn2.pt\"\n",
    "    },\n",
    "    \"test1\": {\n",
    "        \"data\": \"/Users/annateruel/Desktop/poster_sfn/calcium/control/test1_C.h5\",\n",
    "        \"centroid\": \"/Users/annateruel/Desktop/poster_sfn/calcium/control/test1_centroid_x.h5\",\n",
    "        \"model\": \"/Users/annateruel/Desktop/poster_sfn/calcium/control/embeddings/test1.pt\"\n",
    "    },\n",
    "    \"test2\": {\n",
    "        \"data\": \"/Users/annateruel/Desktop/poster_sfn/calcium/control/test2_C.h5\",\n",
    "        \"centroid\": \"/Users/annateruel/Desktop/poster_sfn/calcium/control/test2_centroid_x.h5\",\n",
    "        \"model\": \"/Users/annateruel/Desktop/poster_sfn/calcium/control/embeddings/test2.pt\"\n",
    "    },\n",
    "    \"neutro\": {\n",
    "        \"data\": \"/Users/annateruel/Desktop/poster_sfn/calcium/control/neutro_C.h5\",\n",
    "        \"centroid\": \"/Users/annateruel/Desktop/poster_sfn/calcium/control/neutro_centroid_x.h5\",\n",
    "        \"model\": \"/Users/annateruel/Desktop/poster_sfn/calcium/control/embeddings/neutro.pt\"\n",
    "    }\n",
    "}\n",
    "\n",
    "models = {}\n",
    "embeddings = {}\n",
    "labels = {}\n",
    "\n",
    "for session, paths in data_files.items():\n",
    "    data = cebra.load_data(file=paths[\"data\"], key='estimates/C')\n",
    "    session_labels = cebra.load_data(file=paths[\"centroid\"], key='centroid_x')\n",
    "    \n",
    "    # Trim labels to match the length of data if necessary\n",
    "    min_samples = min(data.shape[0], session_labels.shape[0])\n",
    "    data = data[:min_samples]\n",
    "    session_labels = session_labels[:min_samples]\n",
    "    \n",
    "    labels[session] = session_labels[:, 0].astype(float)  # Ensure labels are 1D floats\n",
    "    model = cebra.CEBRA.load(paths[\"model\"])\n",
    "    models[session] = model\n",
    "    embeddings[session] = model.transform(data)\n",
    "    \n",
    "    # Verify the lengths and shapes\n",
    "    print(f\"Length of data ({session}): {len(data)}\")\n",
    "    print(f\"Length of labels ({session}): {len(session_labels)}\")\n",
    "    print(f\"Shape of embeddings ({session}): {embeddings[session].shape}\")\n",
    "    print(f\"Shape of labels ({session}): {labels[session].shape}\")\n",
    "\n",
    "# Function to compute CCA similarity between two sets of embeddings\n",
    "def compute_cca_similarity(embedding1, embedding2, n_components=10):\n",
    "    min_length = min(embedding1.shape[0], embedding2.shape[0])\n",
    "    embedding1 = embedding1[:min_length]\n",
    "    embedding2 = embedding2[:min_length]\n",
    "    \n",
    "    cca = CCA(n_components=n_components)\n",
    "    cca.fit(embedding1, embedding2)\n",
    "    X_c, Y_c = cca.transform(embedding1, embedding2)\n",
    "    \n",
    "    correlations = [np.corrcoef(X_c[:, i], Y_c[:, i])[0, 1] for i in range(n_components)]\n",
    "    return np.mean(correlations)\n",
    "\n",
    "# Calculate mean embeddings per label\n",
    "def get_mean_per_label(embedding, label):\n",
    "    unique_labels = np.unique(label)\n",
    "    mean_embeddings = np.array([embedding[label == ul].mean(axis=0) for ul in unique_labels])\n",
    "    return mean_embeddings\n",
    "\n",
    "# Compute consistency using CCA for each session\n",
    "session_keys = list(embeddings.keys())\n",
    "mean_embeddings = {session: get_mean_per_label(embeddings[session], labels[session]) for session in session_keys}\n",
    "\n",
    "# Calculate CCA consistency scores\n",
    "def calculate_cca_consistency_scores(emb, dataset_ids=[]):\n",
    "    if isinstance(emb, dict):\n",
    "        emb = list(emb.values())\n",
    "    if len(emb) <= 1:\n",
    "        raise ValueError(\"Provide at least 2 embeddings to compare.\")\n",
    "    if len(dataset_ids) == 0:\n",
    "        dataset_ids = list(range(len(emb)))\n",
    "    if len(emb) != len(dataset_ids):\n",
    "        raise ValueError(\"The number of embeddings must match the number of dataset IDs.\")\n",
    "    \n",
    "    scores = []\n",
    "    pairs = []\n",
    "    n_components = min([embedding.shape[1] for embedding in emb])  # Use the smallest number of components\n",
    "    \n",
    "    for i in range(len(emb)):\n",
    "        for j in range(i + 1, len(emb)):\n",
    "            embedding1 = emb[i]\n",
    "            embedding2 = emb[j]\n",
    "            min_length = min(embedding1.shape[0], embedding2.shape[0])\n",
    "            embedding1 = embedding1[:min_length]\n",
    "            embedding2 = embedding2[:min_length]\n",
    "            \n",
    "            cca = CCA(n_components=n_components)\n",
    "            cca.fit(embedding1, embedding2)\n",
    "            X_c, Y_c = cca.transform(embedding1, embedding2)\n",
    "            \n",
    "            correlations = [np.corrcoef(X_c[:, k], Y_c[:, k])[0, 1] for k in range(n_components)]\n",
    "            score = np.mean(correlations)\n",
    "            \n",
    "            scores.append(score)\n",
    "            pairs.append((dataset_ids[i], dataset_ids[j]))\n",
    "    \n",
    "    return scores, pairs\n",
    "\n",
    "# Calculate CCA consistency scores\n",
    "scores, pairs = calculate_cca_consistency_scores(mean_embeddings, session_keys)\n",
    "\n",
    "# Create a matrix for visualization\n",
    "n_sessions = len(session_keys)\n",
    "consistency_matrix = np.zeros((n_sessions, n_sessions))\n",
    "\n",
    "for (i, j), score in zip(pairs, scores):\n",
    "    idx_i = session_keys.index(i)\n",
    "    idx_j = session_keys.index(j)\n",
    "    consistency_matrix[idx_i, idx_j] = score\n",
    "    consistency_matrix[idx_j, idx_i] = score\n",
    "\n",
    "# Plot the consistency scores\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax1 = plt.subplot(121)\n",
    "ax1.grid(False)\n",
    "\n",
    "sns.heatmap(consistency_matrix, annot=True, fmt=\".2f\", cmap=\"Purples\", xticklabels=session_keys, yticklabels=session_keys, ax=ax1)\n",
    "ax1.set_title(\"CCA-based session consistency\")\n",
    "plt.savefig('/Users/annateruel/Desktop/consistency_3m.svg', format='svg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cebra\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cross_decomposition import CCA\n",
    "\n",
    "# Load data and transform using CEBRA models for AD22-118\n",
    "data_files_ad22 = {\n",
    "    \"conhab2\": {\n",
    "        \"data\": \"/Users/annateruel/Desktop/AD22-118/hab2/caiman/aligned_C.h5\",\n",
    "        \"labels\": \"/Users/annateruel/Desktop/AD22-118/hab2/CEBRA/labels.h5\",\n",
    "        \"model\": \"/Users/annateruel/Desktop/AD22-118/hab2/CEBRA/cebramodelcaiman.pt\"\n",
    "    },\n",
    "    \"contrn1\": {\n",
    "        \"data\": \"/Users/annateruel/Desktop/AD22-118/trn1/caiman/aligned_C.h5\",\n",
    "        \"labels\": \"/Users/annateruel/Desktop/AD22-118/trn1/CEBRA/labels.h5\",\n",
    "        \"model\": \"/Users/annateruel/Desktop/AD22-118/trn1/CEBRA/cebramodelcaiman.pt\"\n",
    "    },\n",
    "    \"contest\": {\n",
    "        \"data\": \"/Users/annateruel/Desktop/AD22-118/test/caiman/aligned_C.h5\",\n",
    "        \"labels\": \"/Users/annateruel/Desktop/AD22-118/test/CEBRA/labels.h5\",\n",
    "        \"model\": \"/Users/annateruel/Desktop/AD22-118/test/CEBRA/cebramodelcaiman.pt\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Load data and transform using CEBRA models for AD23-120\n",
    "data_files_ad23 = {\n",
    "    \"alzhab2\": {\n",
    "        \"data\": \"/Users/annateruel/Desktop/AD23-120/hab2/caiman/aligned_C.h5\",\n",
    "        \"labels\": \"/Users/annateruel/Desktop/AD23-120/hab2/CEBRA/labels.h5\",\n",
    "        \"model\": \"/Users/annateruel/Desktop/AD23-120/hab2/CEBRA/cebramodelcaiman.pt\"\n",
    "    },\n",
    "    \"alztrn1\": {\n",
    "        \"data\": \"/Users/annateruel/Desktop/AD23-120/trn1/caiman/aligned_C.h5\",\n",
    "        \"labels\": \"/Users/annateruel/Desktop/AD23-120/trn1/CEBRA/labels.h5\",\n",
    "        \"model\": \"/Users/annateruel/Desktop/AD23-120/trn1/CEBRA/cebramodelcaiman.pt\"\n",
    "    },\n",
    "    \"alztest\": {\n",
    "        \"data\": \"/Users/annateruel/Desktop/AD23-120/test1/caiman/aligned_C.h5\",\n",
    "        \"labels\": \"/Users/annateruel/Desktop/AD23-120/test1/CEBRA/labels.h5\",\n",
    "        \"model\": \"/Users/annateruel/Desktop/AD23-120/test1/CEBRA/cebramodelcaiman.pt\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def load_transform_data(data_files):\n",
    "    models = {}\n",
    "    embeddings = {}\n",
    "    labels = {}\n",
    "\n",
    "    for session, paths in data_files.items():\n",
    "        data = cebra.load_data(file=paths[\"data\"])\n",
    "        session_labels = cebra.load_data(file=paths[\"labels\"])\n",
    "        \n",
    "        # Trim labels to match the length of data if necessary\n",
    "        min_samples = min(data.shape[0], session_labels.shape[0])\n",
    "        data = data[:min_samples]\n",
    "        session_labels = session_labels[:min_samples]\n",
    "        \n",
    "        labels[session] = session_labels[:, 0].astype(float)  # Ensure labels are 1D floats\n",
    "        model = cebra.CEBRA.load(paths[\"model\"])\n",
    "        models[session] = model\n",
    "        embeddings[session] = model.transform(data)\n",
    "        \n",
    "        # Verify the lengths and shapes\n",
    "        print(f\"Length of data ({session}): {len(data)}\")\n",
    "        print(f\"Length of labels ({session}): {len(session_labels)}\")\n",
    "        print(f\"Shape of embeddings ({session}): {embeddings[session].shape}\")\n",
    "        print(f\"Shape of labels ({session}): {labels[session].shape}\")\n",
    "    \n",
    "    return models, embeddings, labels\n",
    "\n",
    "models_ad22, embeddings_ad22, labels_ad22 = load_transform_data(data_files_ad22)\n",
    "models_ad23, embeddings_ad23, labels_ad23 = load_transform_data(data_files_ad23)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_per_label(embedding, label):\n",
    "    unique_labels = np.unique(label)\n",
    "    mean_embeddings = np.array([embedding[label == ul].mean(axis=0) for ul in unique_labels])\n",
    "    return mean_embeddings\n",
    "\n",
    "mean_embeddings_ad22 = {session: get_mean_per_label(embeddings_ad22[session], labels_ad22[session]) for session in embeddings_ad22.keys()}\n",
    "mean_embeddings_ad23 = {session: get_mean_per_label(embeddings_ad23[session], labels_ad23[session]) for session in embeddings_ad23.keys()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cca_consistency_between_animals(emb1, emb2):\n",
    "    scores = []\n",
    "    pairs = []\n",
    "    n_components = min([embedding.shape[1] for embedding in emb1.values()] + [embedding.shape[1] for embedding in emb2.values()])  # Use the smallest number of components\n",
    "    \n",
    "    for key1, embedding1 in emb1.items():\n",
    "        for key2, embedding2 in emb2.items():\n",
    "            min_length = min(embedding1.shape[0], embedding2.shape[0])\n",
    "            embedding1 = embedding1[:min_length]\n",
    "            embedding2 = embedding2[:min_length]\n",
    "            \n",
    "            cca = CCA(n_components=n_components)\n",
    "            cca.fit(embedding1, embedding2)\n",
    "            X_c, Y_c = cca.transform(embedding1, embedding2)\n",
    "            \n",
    "            correlations = [np.corrcoef(X_c[:, k], Y_c[:, k])[0, 1] for k in range(n_components)]\n",
    "            score = np.mean(correlations)\n",
    "            \n",
    "            scores.append(score)\n",
    "            pairs.append((key1, key2))\n",
    "    \n",
    "    return scores, pairs\n",
    "\n",
    "# Calculate CCA consistency scores between animals\n",
    "scores_between_animals, pairs_between_animals = calculate_cca_consistency_between_animals(mean_embeddings_ad22, mean_embeddings_ad23)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a matrix for visualization\n",
    "session_keys_ad22 = list(mean_embeddings_ad22.keys())\n",
    "session_keys_ad23 = list(mean_embeddings_ad23.keys())\n",
    "n_sessions_ad22 = len(session_keys_ad22)\n",
    "n_sessions_ad23 = len(session_keys_ad23)\n",
    "\n",
    "consistency_matrix_between_animals = np.zeros((n_sessions_ad22, n_sessions_ad23))\n",
    "\n",
    "for (key1, key2), score in zip(pairs_between_animals, scores_between_animals):\n",
    "    idx1 = session_keys_ad22.index(key1)\n",
    "    idx2 = session_keys_ad23.index(key2)\n",
    "    consistency_matrix_between_animals[idx1, idx2] = score\n",
    "\n",
    "# Plot the consistency scores\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax1 = plt.subplot(121)\n",
    "ax1.grid(False)\n",
    "\n",
    "sns.heatmap(consistency_matrix_between_animals, annot=True, fmt=\".2f\", cmap=\"Purples\", xticklabels=session_keys_ad23, yticklabels=session_keys_ad22, ax=ax1)\n",
    "ax1.set_title(\"CCA-based consistency between animals\")\n",
    "plt.savefig('/Users/annateruel/Desktop/betweenanimals.svg', format='svg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the data: behavior and neural activity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,3), dpi=150)\n",
    "plt.subplots_adjust(wspace = 0.3)\n",
    "ax = plt.subplot(121)\n",
    "ax.imshow(nd.T, aspect = 'auto', cmap = 'gray_r')\n",
    "plt.ylabel('Neuron #')\n",
    "plt.xlabel('Time [s]')\n",
    "\n",
    "ax2 = plt.subplot(122)\n",
    "ax2.scatter(np.arange(1000), b[:1000,0], c = 'gray', s=1)\n",
    "plt.ylabel('Position [m]')\n",
    "plt.xlabel('Time [s]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "dir = '/Users/annateruel/phd_code/cebra/AD22118/'\n",
    "file_list = [files for files in os.listdir(dir) if files.endswith('.pt')]\n",
    "file_list = np.sort(file_list)\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_directory = '/Users/annateruel/phd_code/cebra/AD22118/'\n",
    "file_directories = []\n",
    "for root, dirs, files in os.walk(root_directory):\n",
    "    for file in files:\n",
    "        if file == 'S_aligned.h5':\n",
    "            # Append the directory path to the list\n",
    "            file_path = os.path.join(root, file)\n",
    "            file_directories.append(file_path)\n",
    "calcium_file = np.sort(file_directories)\n",
    "calcium_file \n",
    "\n",
    "root_directory = '/Users/annateruel/phd_code/cebra/AD22118/'\n",
    "file_directories = []\n",
    "for root, dirs, files in os.walk(root_directory):\n",
    "    for file in files:\n",
    "        if file == 'centroid.h5':\n",
    "            # Append the directory path to the list\n",
    "            file_path = os.path.join(root, file)\n",
    "            file_directories.append(file_path)\n",
    "beh_file = np.sort(file_directories)\n",
    "beh_file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('dark_background')  # plots with black background\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "\n",
    "ax1 = plt.subplot(241, projection='3d')\n",
    "ax2 = plt.subplot(242, projection='3d')\n",
    "ax3 = plt.subplot(243, projection='3d')\n",
    "ax4 = plt.subplot(244, projection='3d')\n",
    "axs_up = [ax1, ax2, ax3, ax4]\n",
    "\n",
    "for session, dataset, dataset2, ax in zip(file_list, calcium_file, beh_file, axs_up):\n",
    "    nd = cebra.load_data(file=dataset)\n",
    "    b =  cebra.load_data(file=dataset2)\n",
    "\n",
    "    cebra_behavior_model = cebra.CEBRA.load(session)\n",
    "    embedding = cebra_behavior_model.transform(nd)\n",
    "\n",
    "    ax=cebra.plot_embedding(ax=ax, embedding=embedding, embedding_labels=b[:,0], title=f\"{session}\", cmap='cebra', dpi = 100, idx_order=(1, 0, 2), figsize= (3, 3))\n",
    "    plt.savefig('/Users/annateruel/Desktop/ad22118.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_list = []\n",
    "labels = []\n",
    "\n",
    "for session, dataset, dataset2 in zip(file_list, calcium_file, beh_file):\n",
    "    nd = cebra.load_data(file=dataset)\n",
    "    b = cebra.load_data(file=dataset2)\n",
    "\n",
    "    cebra_behavior_model = cebra.CEBRA.load(session)\n",
    "    cebra_behavior_embedding = cebra_behavior_model.transform(nd)\n",
    "\n",
    "    # Append the embedding to the list\n",
    "    embeddings_list.append(cebra_behavior_embedding)\n",
    "    labels.append(b[:,0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    if len(embeddings_list[i]) == len(labels[i]):\n",
    "        print(True)\n",
    "    else: \n",
    "        print(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posdir_scores, posdir_pairs, posdir_subjects = cebra.sklearn.metrics.consistency_score(embeddings=[embeddings_list[0], embeddings_list[1]],\n",
    "                                                                                       labels=[labels[0], labels[1]],\n",
    "                                                                                       between=\"datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cebra\n",
    "\n",
    "plt.style.use('dark_background')  # plots with black background\n",
    "\n",
    "# Directory containing the files\n",
    "directory = '/Users/annateruel/phd_code/cebra/AD22118/'\n",
    "\n",
    "# Iterate over the files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    # Check if the filename matches the structure\n",
    "    if filename.startswith(\"cebra_behavior_model_\") and filename.endswith(\".pt\"):\n",
    "        # Load the model\n",
    "        cebra_behavior_model = cebra.CEBRA.load(os.path.join(directory, filename))\n",
    "\n",
    "        # Transform the model and save it as an embedding\n",
    "        embedding = cebra_behavior_model.transform(nd)\n",
    "\n",
    "        # Create a new figure for each file\n",
    "        fig = plt.figure(figsize=(10,6))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "        # Plot the embedding\n",
    "        ax = cebra.plot_embedding(ax=ax, embedding=embedding, embedding_labels=b[:,0], title=f\"{filename}\", cmap='cebra', dpi = 100, idx_order=(1, 0, 2), figsize= (3, 3))\n",
    "\n",
    "        # Save the figure\n",
    "        plt.savefig(f'/Users/annateruel/Desktop/{filename}.pdf', format='pdf')\n",
    "\n",
    "        # Close the figure to free up memory\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CEBRA-hybrid\n",
    "\n",
    "Uses both time and positional information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "nd = cebra.load_data(file='/Users/annateruel/Desktop/AD23-120/trn1/caiman/aligned_C.h5')\n",
    "b = cebra.load_data(file='/Users/annateruel/Desktop/results_calcium/AD22118/session4/centroid.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iterations = 5000\n",
    "cebra_hybrid_model = CEBRA(model_architecture='offset10-model',\n",
    "                        batch_size=512,\n",
    "                        learning_rate=0.05,\n",
    "                        temperature=1,\n",
    "                        output_dimension=16,\n",
    "                        max_iterations=max_iterations,\n",
    "                        distance='cosine',\n",
    "                        conditional='time_delta',\n",
    "                        device='mps',\n",
    "                        verbose=True,\n",
    "                        time_offsets=10,\n",
    "                        hybrid = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cebra_hybrid_model.fit(nd, b)\n",
    "cebra_hybrid_model.save(\"cebra_hybrid_model_s4.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cebra_hybrid_model = cebra.CEBRA.load(\"cebra_hybrid_model.pt\")\n",
    "cebra_hybrid = cebra_hybrid_model.transform(nd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cebra.plot_embedding(ax=ax1, embedding=cebra_behavior, embedding_labels=b_s4[:,1], title='CEBRA-Behavior Session1', cmap='plasma')\n",
    "plt.savefig('/Users/annateruel/Desktop/your_plot.svg', format='svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search (hyperparameter tuning)\n",
    "\n",
    "A grid-search is the process of performing hyperparameter tuning in order to determine the optimal values of a given model. Practically, it consists in running a model on the data, by modifying the hyperparameters values at each iteration. Then, evaluating the performances of each model allows the user to select the best set of hyperparameters for its specific data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cebra\n",
    "# 1. Define the parameters, either variable or fixed\n",
    "params_grid = dict(\n",
    "    output_dimension = [3,16],\n",
    "    learning_rate = [0.005, 0.01, 0.05],\n",
    "    time_offsets = 5,\n",
    "    max_iterations = 500,\n",
    "    device='mps',\n",
    "    temperature_mode = \"auto\",\n",
    "    verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\"dataset1\": nd,                     \n",
    "            \"dataset2\": (nd, b)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = cebra.grid_search.GridSearch()\n",
    "grid_search.fit_models(datasets=datasets, params=params_grid, models_dir=\"saved_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = grid_search.get_df_results(models_dir=\"saved_models2\")\n",
    "best_model, best_model_name = grid_search.get_best_model(dataset_name=\"dataset2\", models_dir=\"saved_models2\")\n",
    "best_model_name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cebram1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
